---
title: "A Replication of Karlan and List (2007)"
author: "Charlotte Hunter"
date: "2025-04-23"
format:
  html:
    callout-appearance: minimal
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).

In the experiment, Karlan and List partnered with a nonprofit organization to explore how different types of donation appeals affect giving behavior. While all recipients were previous donors, the letters varied in key ways: some offered no incentive, while others included matching grants of $1:$1, $2:$1, or $3:$1, where a “leadership donor” pledged to match donations up to a certain amount. The letters also varied the suggested contribution amount and the cap on how much the leadership donor would match.

By randomly assigning these conditions and tracking donations in response, the researchers were able to estimate how changes in perceived “price” and framing influenced both the probability of donating and the total amount given. This project seeks to replicate their findings using the original data and statistical approach.

This project seeks to replicate their results.

## Data

### Description

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# Load libraries
library(haven)
library(dplyr)

df <- read_dta("~/Desktop/karlan_list_2007.dta")
```

The dataset karlan_list_2007.dta captures the results of a large-scale field experiment on charitable giving, involving 50,083 previous donors to a nonprofit organization. Each row in the dataset represents one individual who received a fundraising letter during the campaign. The experimental design randomly assigned participants to a control group or to one of several treatment groups, which varied along three key dimensions: the match ratio offered (1:1, 2:1, or 3:1), the maximum size of the matching grant ($25,000, $50,000, $100,000, or unstated), and the suggested donation amount (based on prior giving history, scaled by 1.0, 1.25, or 1.5). The dataset records whether the individual made a donation (gave) and how much they donated (amount). It also contains detailed prior giving history, including the number of past donations, recency of giving, and highest previous contribution. Demographic information is included at the zip-code level, such as racial composition (pwhite, pblack), median household income, average household size, homeownership rates, and educational attainment. Additionally, political context is captured through indicators for whether the individual lived in a red or blue state or county during the 2004 presidential election. This rich set of variables enables analysis not only of overall treatment effects but also of heterogeneous effects across political and demographic subgroups.

:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::

### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

names(df)

<!--_todo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)._-->

```{r, echo=FALSE}
# ========== mrm2 ==========
cat("### Linear Regression: mrm2 ~ treatment\n\n")
model_mrm2 <- lm(mrm2 ~ treatment, data = df)
printCoefmat(summary(model_mrm2)$coefficients, signif.stars = TRUE)
cat("\n\n")

# ========== female ==========
cat("### Linear Regression: female ~ treatment\n\n")
model_female <- lm(female ~ treatment, data = df)
printCoefmat(summary(model_female)$coefficients, signif.stars = TRUE)
cat("\n\n")

# ========== years ==========
cat("### Linear Regression: years ~ treatment\n\n")
model_years <- lm(years ~ treatment, data = df)
printCoefmat(summary(model_years)$coefficients, signif.stars = TRUE)
```

To test whether the treatment and control groups were balanced before the experiment began, I ran both a t-test and a linear regression using the variable mrm2, which represents months since last donation. The t-test yielded a t-statistic of approximately 0.12, indicating no statistically significant difference between the groups. I then ran a linear regression of mrm2 on the treatment variable. The coefficient on treatment was nearly zero and not statistically significant, confirming the same result: the groups were balanced. This matches the purpose of Table 1 in the paper, which is to verify that the randomization was successful and that the treatment groups were similar before the intervention. This helps isolate the causal effect of the fundraising treatments observed later in the study.

## Experimental Results

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

<!--_todo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control._-->

```{r, echo=FALSE}
# summary table
library(ggplot2)
library(dplyr)
donation_rates <- df %>%
  group_by(treatment) %>%
  summarise(proportion_donated = mean(gave, na.rm = TRUE)) %>%
  mutate(group = ifelse(treatment == 1, "Treatment", "Control"))

# plot
ggplot(donation_rates, aes(x = group, y = proportion_donated)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Proportion of People Who Donated",
    x = "",
    y = "Proportion Donated"
  ) +
  scale_y_continuous(
    breaks = seq(0, 0.03, by = 0.005),
    limits = c(0, 0.03)
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

This bar plot shows the proportion of people who donated in each group. The treatment group, which received a fundraising letter mentioning a matching donation, had a slightly higher donation rate than the control group. While both rates are low overall, the visual difference suggests that even a small change in how the request was framed — in this case, offering a match — may have encouraged more people to give.

<!--_todo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)_-->

```{r, echo=FALSE, results='asis'}

# --- Manual t-test ---
gave_treat <- df$gave[df$treatment == 1]
gave_control <- df$gave[df$treatment == 0]

mean_treat <- mean(gave_treat, na.rm = TRUE)
mean_control <- mean(gave_control, na.rm = TRUE)

var_treat <- mean_treat * (1 - mean_treat)
var_control <- mean_control * (1 - mean_control)

n_treat <- sum(!is.na(gave_treat))
n_control <- sum(!is.na(gave_control))

t_stat <- (mean_treat - mean_control) / sqrt((var_treat / n_treat) + (var_control / n_control))

cat("### Manual T-Test: gave ~ treatment\n")
cat("**Calculated t-statistic:** ", round(t_stat, 4), "\n\n")

# --- Linear regression ---
cat("### Linear Regression: gave ~ treatment\n")
model <- lm(gave ~ treatment, data = df)
printCoefmat(summary(model)$coefficients, signif.stars = TRUE)
```

I compared the proportion of people who donated in the treatment and control groups. In the control group, about 1.8% of individuals donated, compared to 2.2% in the treatment group. Although this seems like a small difference, a statistical test showed that it is highly unlikely to have occurred by chance. I confirmed this result using both a t-test (following the class formula) and a simple linear regression. Both methods showed the same result — that people who received a matching grant letter were significantly more likely to give.

This tells us something important about human behavior: even a small change in how a request is framed — like offering to match someone’s donation — can meaningfully affect whether they decide to act. The offer likely made giving feel more impactful or urgent. This kind of result is exactly what Table 2A in the paper is highlighting: how relatively subtle changes in message framing can lead to statistically and practically meaningful behavior change.

<!--_todo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper._-->

```{r, echo=FALSE}
# probit model
probit_model <- glm(gave ~ treatment, data = df, family = binomial(link = "probit"))
summary(probit_model)
```
I ran a probit regression where the outcome variable was whether an individual donated (gave) and the explanatory variable was whether they were assigned to a treatment group (treatment). The coefficient on treatment was small but positive and statistically significant, replicating the result shown in Table 3, Column 1 of the Karlan & List paper. This suggests that receiving a letter with a matching grant offer had a statistically significant effect on the probability of donating, even after accounting for the binary nature of the outcome variable using a probit model.

### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.

<!--_todo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the "figures suggest" comment the authors make on page 8?_-->

```{r, echo=FALSE}
# filter to matches
match_data <- df %>% filter(ratio %in% c("1", "2", "3"))

# 2:1 vs 1:1
# conver character to numeric 
match_1v2 <- match_data %>% filter(ratio %in% c("1", "2"))
t.test(gave ~ ratio, data = match_1v2)

# 3:1 vs 1:1
match_1v3 <- match_data %>% filter(ratio %in% c("1", "3"))
t.test(gave ~ ratio, data = match_1v3)

# 3:1 vs 2:1
match_2v3 <- match_data %>% filter(ratio %in% c("2", "3"))
t.test(gave ~ ratio, data = match_2v3)
```
To test whether larger match ratios increase the likelihood of donating, I ran a series of t-tests comparing donation rates between the 1:1, 2:1, and 3:1 match groups. The results showed no statistically significant differences. The 2:1 and 3:1 groups had slightly higher donation rates than the 1:1 group (about 2.27% vs. 2.07%), but these differences were small and not statistically meaningful (p-values > 0.30). A comparison between the 2:1 and 3:1 groups yielded almost identical results, with a p-value of 0.96. These findings support the authors' claim on page 8 that increasing the match ratio beyond 1:1 does not further increase giving. This suggests that the presence of a match may be what matters most — once donors see their contribution will be matched, making the match larger does not add much persuasive power.

<!--_todo: Assess the same issue using a regression. Specifically, create the variable `ratio1` then regress `gave` on `ratio1`, `ratio2`, and `ratio3` (or alternatively, regress `gave` on the categorical variable `ratio`). Interpret the coefficients and their statistical precision._-->

```{r, echo=FALSE}
match_data$ratio <- factor(match_data$ratio)

# 1:1
lm(gave ~ ratio, data = match_data) %>% summary()
```
In the regression model comparing match ratios, the 1:1 match group had a baseline donation rate of approximately 2.07%. The 2:1 and 3:1 match groups showed slightly higher estimated donation rates—about 0.19 and 0.20 percentage points more, respectively—but these differences were not statistically significant. Both coefficients had relatively large standard errors and high p-values (above 0.3), indicating low statistical precision. This means we cannot confidently say that higher match ratios had any real effect beyond the 1:1 match. These results support the conclusion that increasing the match ratio does not significantly influence the likelihood of donating.


<!--_todo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios.  Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?_-->


### Size of Charitable Contribution

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.

<!-- _todo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?_-->

```{r, echo=FALSE}
# mean donation rates
means_by_ratio <- match_data %>%
  group_by(ratio) %>%
  summarise(response_rate = mean(gave, na.rm = TRUE))
means_by_ratio

# 2:1 to 1:1
diff_2v1 <- means_by_ratio$response_rate[means_by_ratio$ratio == "2"] -
            means_by_ratio$response_rate[means_by_ratio$ratio == "1"]

# 3:1 to 2:1
diff_3v2 <- means_by_ratio$response_rate[means_by_ratio$ratio == "3"] -
            means_by_ratio$response_rate[means_by_ratio$ratio == "2"]
            
model <- lm(gave ~ ratio, data = match_data)
summary(model)

coef_1v2 <- coef(model)["ratio2"] 
coef_2v3 <- coef(model)["ratio3"] - coef(model)["ratio2"] 
```

I calculated the difference in response rates between the 1:1 and 2:1 match groups, and between the 2:1 and 3:1 groups, both directly from the data and using the coefficients from a linear regression. In both cases, the differences were very small—around 0.19 percentage points for 2:1 vs. 1:1, and essentially zero for 3:1 vs. 2:1. These results suggest that increasing the size of the matching donation beyond 1:1 has minimal to no effect on whether people choose to give. The consistency between the raw data and regression confirms that larger match ratios do not meaningfully improve donation rates, reinforcing the idea that simply offering a match may matter more than how generous the match actually is.
 
<!-- _todo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients -- what did we learn? Does the treatment coefficient have a causal interpretation?_ -->

```{r, echo=FALSE}
# donors only
donors_only <- match_data %>% filter(gave == 1)

donors_only$ratio <- factor(donors_only$ratio)  # make sure it's a factor
model_donation_amt <- lm(amount ~ ratio, data = donors_only)
summary(model_donation_amt)
```

I ran a regression to examine whether the size of the match ratio influenced how much people donated, among those who chose to give. The results showed no statistically significant differences between the 1:1, 2:1, and 3:1 groups. Donors in the 2:1 group gave about 19 cents more than the 1:1 group, and donors in the 3:1 group gave about $3.89 less, but neither difference was meaningful or statistically reliable. However, this regression does not have a valid causal interpretation, since it only includes people who donated — a post-treatment outcome that breaks the randomization. As a result, we cannot conclude whether the match ratio itself caused any differences in donation amounts.

<!-- _todo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot._ -->

```{r, echo=FALSE, warning=FALSE}
# treatment group histogram
donors_treat <- donors_only %>% filter(treatment == 1)
mean_treat <- mean(donors_treat$amount, na.rm = TRUE)
ggplot(donors_treat, aes(x = amount)) +
  geom_histogram(binwidth = 5, fill = "skyblue", color = "white") +
  geom_vline(xintercept = mean_treat, color = "red", linetype = "dashed", size = 1) +
  labs(
    title = "Donations Among Treatment Group (Gave == 1)",
    x = "Donation Amount ($)",
    y = "Number of Donors"
  ) +
  annotate("text", x = mean_treat, y = 5,
           label = paste0("Mean = $", round(mean_treat, 2)),
           color = "red", vjust = -0.5) +
  xlim(0, max(donors_treat$amount, na.rm = TRUE) + 10) +
  theme_minimal()

# regenerate control data
donors_only <- df %>% filter(gave == 1)  # from full df, not match_data
donors_control <- donors_only %>% filter(treatment == 0)
mean_control <- mean(donors_control$amount, na.rm = TRUE)

# control group histogram
ggplot(donors_control, aes(x = amount)) +
  geom_histogram(binwidth = 5, fill = "lightgreen", color = "white") +
  geom_vline(xintercept = mean_control, color = "red", linetype = "dashed", size = 1) +
  labs(
    title = "Donations Among Control Group (Gave == 1)",
    x = "Donation Amount ($)",
    y = "Number of Donors"
  ) +
  annotate("text", x = mean_control, y = 5,
           label = paste0("Mean = $", round(mean_control, 2)),
           color = "red", vjust = -0.5) +
  xlim(0, max(donors_control$amount, na.rm = TRUE) + 10) +
  theme_minimal()
```

## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.

### Law of Large Numbers

<!-- _to do:  Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You'll then calculate a vector of 10,000 differences, and then you'll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means._ -->

```{r, echo=FALSE, warning=FALSE}
# control & treatment donation 
control_donors <- df %>% filter(treatment == 0 & gave == 1)
treat_donors <- df %>% filter(treatment == 1 & gave == 1)

mean_control <- mean(control_donors$amount, na.rm = TRUE)
sd_control <- sd(control_donors$amount, na.rm = TRUE)

mean_treat <- mean(treat_donors$amount, na.rm = TRUE)
sd_treat <- sd(treat_donors$amount, na.rm = TRUE)

# simulate
set.seed(123) 
sim_control <- rnorm(100000, mean = mean_control, sd = sd_control)
sim_treat <- rnorm(10000, mean = mean_treat, sd = sd_treat)

sim_diff <- sim_treat - sample(sim_control, 10000, replace = TRUE)
cumulative_avg <- cumsum(sim_diff) / seq_along(sim_diff)

# plot
plot(cumulative_avg, type = "l", col = "blue", lwd = 2,
     main = "Cumulative Average of Treatment - Control Differences",
     xlab = "Number of Simulated Pairs",
     ylab = "Cumulative Average Difference")
abline(h = mean_treat - mean_control, col = "red", lty = 2)
legend("bottomright", legend = "True Difference", col = "red", lty = 2)
```
This plot shows the cumulative average of differences in donation amounts between the treatment and control groups, based on simulated data. I drew 10,000 values from the treatment group distribution and compared each to a randomly drawn value from the control group distribution. Each point on the blue line represents the average difference after one more simulated pair. As expected, the early differences are highly variable, but the line stabilizes as more data accumulate. The red dashed line represents the actual difference in means from the real data. The fact that the blue line converges to this value illustrates a key concept in statistics: with enough data, sampling variation averages out, and the sample-based estimate approaches the true effect.


### Central Limit Theorem

<!--_to do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the "middle" of the distribution or whether it's in the "tail."_ -->

```{r, echo=FALSE, warning=FALSE}
# control & treatment 
mean_control <- mean(control_donors$amount, na.rm = TRUE)
sd_control <- sd(control_donors$amount, na.rm = TRUE)
mean_treat <- mean(treat_donors$amount, na.rm = TRUE)
sd_treat <- sd(treat_donors$amount, na.rm = TRUE)

# simulate
simulate_diff_dist <- function(n, reps = 1000) {
  replicate(reps, {
    sample_treat <- rnorm(n, mean_treat, sd_treat)
    sample_control <- rnorm(n, mean_control, sd_control)
    mean(sample_treat) - mean(sample_control)
  })
}

# plots
library(ggplot2)

sample_sizes <- c(50, 200, 500, 1000)
par(mfrow = c(2, 2))  # 2x2 plot layout

for (n in sample_sizes) {
  diffs <- simulate_diff_dist(n)
  hist(diffs,
       breaks = 30,
       main = paste("Sample Size =", n),
       xlab = "Avg Treatment - Control",
       col = "lightblue",
       border = "white")
  abline(v = 0, col = "red", lwd = 2, lty = 2)
}
```

These histograms show the distribution of estimated treatment effects across 1,000 simulations for sample sizes of 50, 200, 500, and 1000. In each simulation, I drew independent samples from the treatment and control distributions and computed the difference in their means. At smaller sample sizes, the distributions are wider and noisier, with the red line at zero appearing near the center. This means that with a small sample, it's quite common to estimate a treatment effect close to zero just by chance — even if a true effect exists. As the sample size increases, the distribution of estimates becomes narrower, and zero shifts toward the tail, particularly in the histogram for sample size 1000. This indicates that with larger samples, it's much less likely for random variation to produce a near-zero estimate when there is a true effect. Overall, the plots illustrate how larger samples reduce sampling variability, increase precision, and improve our ability to detect real treatment effects, especially when those effects are small.


